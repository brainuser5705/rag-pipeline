{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG System with Unstructured, Qdrant, and OpenAI\n",
    "\n",
    "This notebook contains code for a Retrieval Augmented Generation (RAG) system. RAG takes in external user-submitted documents to be used as context for Large Language Models (LLM). \n",
    "\n",
    "Due to limitations of LLM token sizes and the importance of quality context, a RAG system has additional steps in its pipeline. It must partition the documents into smaller pieces and \"chunk\" them together. The chunk contains the information needed by the LLM, as well as additional background knowledge, to provide the LLM with the best context. This requires searching which part of the document contains the information, and that is done by turning the chunks into embeddings. All of these steps are features that should be implemented in a RAG system.\n",
    "\n",
    "## System Overview\n",
    "\n",
    "- Unstructured - partitions the documents and chunks them together\n",
    "- embedding models\n",
    "- Qdrant - vector data store for storing and querying embeddings\n",
    "- OpenAI - LLM model for producing final response\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "UNSTRUCTURED_API_KEY = os.getenv(\"UNSTRUCTURED_API_KEY\")\n",
    "UNSTRUCTURED_API_URL = os.getenv(\"UNSTRUCTURED_API_URL\")\n",
    "\n",
    "LOCAL_FILE_INPUT_DIR = os.getenv(\"LOCAL_FILE_INPUT_DIR\")\n",
    "LOCAL_FILE_OUTPUT_DIR = os.getenv(\"LOCAL_FILE_OUTPUT_DIR\")\n",
    "\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-l6-v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Ingestion\n",
    "\n",
    "This phase uses Unstructued to convert documents into chunks.\n",
    "\n",
    "Notes:\n",
    "- Using Unstructured Ingest Python Library because we are batch processing multiple files\n",
    "- Source connector is to a local directory.\n",
    "- Destination connector is to the Qdrant database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n",
      "2024-09-25 08:56:26,753 MainProcess INFO     created index with configs: {\"input_path\": \"data\", \"recursive\": false}, connection configs: {\"access_config\": \"**********\"}\n",
      "2024-09-25 08:56:26,755 MainProcess INFO     Created download with configs: {\"download_dir\": null}, connection configs: {\"access_config\": \"**********\"}\n",
      "2024-09-25 08:56:26,756 MainProcess INFO     created partition with configs: {\"strategy\": \"hi_res\", \"ocr_languages\": null, \"encoding\": null, \"additional_partition_args\": {\"split_pdf_page\": true, \"split_pdf_allow_failed\": true, \"split_pdf_concurrency_level\": 15}, \"skip_infer_table_types\": null, \"fields_include\": [\"element_id\", \"text\", \"type\", \"metadata\", \"embeddings\"], \"flatten_metadata\": false, \"metadata_exclude\": [], \"metadata_include\": [], \"partition_endpoint\": \"https://api.unstructured.io/general/v0/general\", \"partition_by_api\": true, \"api_key\": \"*******\", \"hi_res_model_name\": null}\n",
      "2024-09-25 08:56:26,757 MainProcess INFO     created embed with configs: {\"embedding_provider\": \"langchain-huggingface\", \"embedding_api_key\": \"*******\", \"embedding_model_name\": \"sentence-transformers/all-MiniLM-l6-v2\", \"embedding_aws_access_key_id\": null, \"embedding_aws_secret_access_key\": null, \"embedding_aws_region\": \"us-west-2\"}\n",
      "2024-09-25 08:56:26,758 MainProcess INFO     Created upload with configs: {\"output_dir\": \"./output\"}, connection configs: {\"access_config\": \"**********\"}\n"
     ]
    }
   ],
   "source": [
    "from unstructured_ingest.v2.pipeline.pipeline import Pipeline\n",
    "from unstructured_ingest.v2.interfaces import ProcessorConfig\n",
    "from unstructured_ingest.v2.processes.connectors.local import (\n",
    "    LocalIndexerConfig,\n",
    "    LocalDownloaderConfig,\n",
    "    LocalConnectionConfig,\n",
    "    LocalUploaderConfig\n",
    ")\n",
    "from unstructured_ingest.v2.processes.partitioner import PartitionerConfig\n",
    "from unstructured_ingest.v2.processes.chunker import ChunkerConfig\n",
    "from unstructured_ingest.v2.processes.embedder import EmbedderConfig\n",
    "\n",
    "pipeline = Pipeline.from_configs(\n",
    "    context=ProcessorConfig(),\n",
    "    indexer_config=LocalIndexerConfig(input_path=LOCAL_FILE_INPUT_DIR),\n",
    "    downloader_config=LocalDownloaderConfig(),\n",
    "    source_connection_config=LocalConnectionConfig(),\n",
    "    partitioner_config=PartitionerConfig(\n",
    "        partition_by_api=True,\n",
    "        api_key=UNSTRUCTURED_API_KEY,\n",
    "        partition_endpoint=UNSTRUCTURED_API_URL,\n",
    "        strategy=\"hi_res\",\n",
    "        additional_partition_args={\n",
    "            \"split_pdf_page\": True,\n",
    "            \"split_pdf_allow_failed\": True,\n",
    "            \"split_pdf_concurrency_level\": 15\n",
    "        }\n",
    "    ),\n",
    "    # chunker_config=ChunkerConfig(chunking_strategy=\"by_title\"),\n",
    "    embedder_config=EmbedderConfig(\n",
    "        embedding_provider=\"langchain-huggingface\",\n",
    "        embedding_model_name=EMBEDDING_MODEL_NAME,\n",
    "        embedding_api_key=HUGGINGFACEHUB_API_TOKEN\n",
    "    ),\n",
    "    uploader_config=LocalUploaderConfig(output_dir=LOCAL_FILE_OUTPUT_DIR)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 08:56:32,243 MainProcess INFO     running local pipeline: index (LocalIndexer) -> download (LocalDownloader) -> partition (hi_res) -> embed (langchain-huggingface) -> upload (LocalUploader) with configs: {\"reprocess\": false, \"verbose\": false, \"tqdm\": false, \"work_dir\": \"C:\\\\Users\\\\codeu\\\\.cache\\\\unstructured\\\\ingest\\\\pipeline\", \"num_processes\": 2, \"max_connections\": null, \"raise_on_error\": false, \"disable_parallelism\": false, \"preserve_downloads\": false, \"download_only\": false, \"re_download\": false, \"uncompress\": false, \"iter_delete\": false, \"delete_cache\": false, \"otel_endpoint\": null, \"status\": {}}\n",
      "2024-09-25 08:56:32,393 MainProcess INFO     index finished in 0.0s\n",
      "2024-09-25 08:56:32,408 MainProcess INFO     calling DownloadStep with 5 docs\n",
      "2024-09-25 08:56:32,408 MainProcess INFO     processing content async\n",
      "2024-09-25 08:56:32,409 MainProcess WARNING  async code being run in dedicated thread pool to not conflict with existing event loop: <_WindowsSelectorEventLoop running=True closed=False debug=False>\n",
      "2024-09-25 08:56:32,419 MainProcess INFO     download finished in 0.0084713s, attributes: file_id=79c28b1e42da\n",
      "2024-09-25 08:56:32,435 MainProcess INFO     download finished in 0.0124951s, attributes: file_id=70fc02b9bdb3\n",
      "2024-09-25 08:56:32,444 MainProcess INFO     download finished in 0.008001s, attributes: file_id=1aed25d53156\n",
      "2024-09-25 08:56:32,458 MainProcess INFO     download finished in 0.0124579s, attributes: file_id=23ff15cc1caa\n",
      "2024-09-25 08:56:32,467 MainProcess INFO     download finished in 0.0073801s, attributes: file_id=684d8d31214a\n",
      "2024-09-25 08:56:32,468 MainProcess INFO     download step finished in 0.060378s\n",
      "2024-09-25 08:56:32,469 MainProcess INFO     calling PartitionStep with 5 docs\n",
      "2024-09-25 08:56:32,470 MainProcess INFO     processing content async\n",
      "2024-09-25 08:56:32,470 MainProcess WARNING  async code being run in dedicated thread pool to not conflict with existing event loop: <_WindowsSelectorEventLoop running=True closed=False debug=False>\n",
      "2024-09-25 08:56:32,479 MainProcess INFO     partition finished in 0.0064094s, attributes: file_id=79c28b1e42da\n",
      "2024-09-25 08:56:32,496 MainProcess INFO     partition finished in 0.0133188s, attributes: file_id=70fc02b9bdb3\n",
      "2024-09-25 08:56:32,505 MainProcess INFO     partition finished in 0.0084715s, attributes: file_id=1aed25d53156\n",
      "2024-09-25 08:56:32,513 MainProcess INFO     partition finished in 0.0071012s, attributes: file_id=23ff15cc1caa\n",
      "2024-09-25 08:56:32,525 MainProcess INFO     partition finished in 0.0107494s, attributes: file_id=684d8d31214a\n",
      "2024-09-25 08:56:32,527 MainProcess INFO     partition step finished in 0.058501s\n",
      "2024-09-25 08:56:32,528 MainProcess INFO     calling EmbedStep with 5 docs\n",
      "2024-09-25 08:56:32,528 MainProcess INFO     processing content across processes\n",
      "2024-09-25 08:56:48,138 MainProcess INFO     embed step finished in 15.6091666s\n",
      "2024-09-25 08:56:48,139 MainProcess INFO     calling UploadStep with 5 docs\n",
      "2024-09-25 08:56:48,140 MainProcess INFO     processing content across processes\n",
      "2024-09-25 08:56:49,346 MainProcess INFO     upload step finished in 1.206878s\n",
      "2024-09-25 08:56:49,347 MainProcess INFO     ingest process finished in 17.1048205s\n"
     ]
    }
   ],
   "source": [
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Qdrant Database\n",
    "\n",
    "The Qdrant database will be storing the vector embeddings of the document chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "\n",
    "COLLECTION_NAME = \"resumes\"\n",
    "\n",
    "client = QdrantClient(url=\"http://localhost:6333\")\n",
    "client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=VectorParams(size=384, distance=Distance.DOT)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Vector Embeddings into Qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a chunk created by Unstructured and inserts it into the Qdrant database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import PointStruct\n",
    "\n",
    "def insert_qdrant_point(chunk):\n",
    "    print(f'Inserting Chunk {chunk[\"element_id\"]}', end=\"\")\n",
    "    status = client.upsert(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        wait=True,\n",
    "        points=[\n",
    "            PointStruct(\n",
    "                id=chunk[\"element_id\"],\n",
    "                vector=chunk[\"embeddings\"],\n",
    "                payload={\n",
    "                    \"text\": chunk[\"text\"],\n",
    "                    \"filename\": chunk[\"metadata\"][\"filename\"], \n",
    "                }), \n",
    "        ]\n",
    "    )\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting Chunk 6fcee20a4414adcca9d0743d2fa4174coperation_id=0 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk 422bca2e1a097ebaa25daf86cc517df9operation_id=1 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk 73a6b890c933664d41b764ba76f27716operation_id=2 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk 6b932145122949306692a4c64d0cf656operation_id=3 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk 706f65324f496588e14faf79ff0dd946operation_id=4 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk ed2e103de56d612df8fbada5ebe74231operation_id=5 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk b20d0d7cf454f440663f0ac17b47697aoperation_id=6 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk 7b871c18de37b63bdba99c6476e09754operation_id=7 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk 1dc452b2ab55cea13fd91951c27ecc2aoperation_id=8 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk dc2ae95d4999b2af6319abfae5e17f0doperation_id=9 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk 15f6e94c236dd23bcd03c3b252a8badboperation_id=10 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk 391b411834ba16a7e7ca4987c247b5f5operation_id=11 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk 270a3fdac73076e95444fe8cb996f729operation_id=12 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk 4510cb73c25b3d9a1f0c32ba73ae8a59operation_id=13 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk 62b278fe5d18507be59396ec1d4dd635operation_id=14 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk 30336365c0b82a87b2b22691f08f418coperation_id=15 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk 603f7044e52102e638c165158f701ed5operation_id=16 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk 35a58efe05ee7d38c0f3ac896b2b812doperation_id=17 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk c228249207f84a6597206c3750b80858operation_id=18 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk fd5cf5966e79d88e63b6e69f6907142boperation_id=19 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk 21316e64634c16a1a36d3f10140b394boperation_id=20 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk 356db0ff70d0f68d1edce51964ca226boperation_id=21 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk c91eb11c51d948d20650fec40c1ed458operation_id=22 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk a42871cb4f3002f8d774430c079d604foperation_id=23 status=<UpdateStatus.COMPLETED: 'completed'>\n",
      "Inserting Chunk e6cdc509f5c33112b12f9b4f11060da0operation_id=24 status=<UpdateStatus.COMPLETED: 'completed'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Output directory of JSON files\n",
    "output_dir = \"./output\"\n",
    "\n",
    "for filename in os.scandir(output_dir):\n",
    "    if filename.is_file():\n",
    "        file = open(filename.path)\n",
    "        file_json = json.load(file)\n",
    "        for chunk in file_json:\n",
    "            insert_qdrant_point(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up LLM and Embedding Model\n",
    "\n",
    "The Embedding Model will be used to create the vector embedding for the user query. The resulting embedding will be used to query Qdrant.\n",
    "\n",
    "The LLM is a HuggingFace ChatModel provided by Langchain. It is used for the text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\codeu\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=10000,\n",
    "    do_sample=False,\n",
    ")\n",
    "model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=HUGGINGFACEHUB_API_TOKEN,\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Who has experience in Aerospace Engineering? Write a full sentence.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Qdrant\n",
    "\n",
    "We can use the embedding model to generate a search vector for Qdrant to get the most similar embedding and retrieve the most relevant document(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "{'text': 'Profile Mechanical engineer with a knack for propulsion systems and a thirst for knowledge. I bring three years of experience at the intersection of technology and defense, eager to elevate aerospace projects at the Air Force Research Laboratory.', 'filename': 'Brian Patel.txt'}\n",
      "---\n",
      "{'text': 'Profile Driven aerospace engineer with a passion for innovation in UAV technology. With over five years of hands-on experience in flight dynamics, I am excited to contribute my expertise to the Air Force Research Laboratory, pushing the boundaries of aerial capabilities.', 'filename': 'Alexandra Johnson.txt'}\n",
      "---\n",
      "{'text': 'Education Bachelor’s in Aerospace Engineering University of Washington, Seattle, WA Graduated: June 2023', 'filename': 'Eva Chen.txt'}\n",
      "---\n",
      "{'text': 'Profile Recent aerospace engineering graduate with hands-on experience in aerodynamic testing. I’m eager to apply my skills and enthusiasm at the Air Force Research Laboratory, contributing to cutting-edge aerospace projects.', 'filename': 'Eva Chen.txt'}\n",
      "---\n",
      "{'text': 'Profile Innovative computer scientist with a passion for aerospace simulation tools. With two years of experience, I’m eager to bring my coding skills to the Air Force Research Laboratory, transforming ideas into reality.', 'filename': 'Chloe Kim.txt'}\n",
      "---\n",
      "{'text': 'Education PhD in Aerospace Engineering University of Dayton, Dayton, OH Graduated: May 2018', 'filename': 'Alexandra Johnson.txt'}\n",
      "---\n",
      "{'text': 'Experience Aerospace Intern Flight Testing Services, Seattle, WA Summer 2022', 'filename': 'Eva Chen.txt'}\n",
      "---\n",
      "{'text': 'Experience Software Developer Aerospace Simulations Inc., Los Angeles, CA June 2021 – Present', 'filename': 'Chloe Kim.txt'}\n",
      "---\n",
      "{'text': 'Profile Materials scientist passionate about advancing aerospace technologies. With four years of research experience, I’m excited to contribute innovative solutions to the Air Force Research Laboratory’s mission.', 'filename': 'David Martinez.txt'}\n",
      "---\n",
      "{'text': 'Conducted wind tunnel tests to evaluate aerodynamic performance of aircraft models. Analyzed data and presented results to engineering teams. Skills Technical Aptitude: Proficient in SolidWorks and MATLAB, essential for design and analysis. Analytical Thinker: Ability to interpret data and draw meaningful conclusions. Team Player: Strong communication skills, enabling effective collaboration with diverse teams.', 'filename': 'Eva Chen.txt'}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "hits = client.query_points(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    query=embeddings.embed_query(user_query),\n",
    ").points\n",
    "\n",
    "retrieved_docs = [hit.payload for hit in hits]\n",
    "print(len(retrieved_docs))\n",
    "for doc in retrieved_docs:\n",
    "    print(doc, end=\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating final response from LLM\n",
    "\n",
    "Now that we have a list of releveant documents, we can append it to the query. The LLM now has more contextual information to give a relevant and correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = model | parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2418"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Here are list of resumes.\"\n",
    "for doc in retrieved_docs:\n",
    "    instruction += \"\\n\" + str(doc)\n",
    "len(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Brian Patel, Alexandra Johnson, Eva Chen, Chloe Kim, and David Martinez all have experience in Aerospace Engineering, as evidenced by their respective resume entries. \\n\\n- Brian Patel's resume states that he is a Mechanical engineer with three years of experience at the intersection of technology and defense, specifically related to propulsion systems and defense.\\n- Alexandra Johnson's resume indicates that she is an aerospace engineer with over five\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(instruction + \"\\n\" + user_query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
